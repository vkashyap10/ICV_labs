{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1277d7",
   "metadata": {},
   "source": [
    "# ICV_labs : Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from matplotlib.pyplot import figure\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10085dec",
   "metadata": {},
   "source": [
    "# Load first frame and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Dataset/DatasetC.mpg'\n",
    "# create directory to store results\n",
    "!mkdir Results\n",
    "!mkdir Results/Q5\n",
    "!mkdir Results/Q5/partA\n",
    "!mkdir Results/Q5/partB\n",
    "!mkdir Results/Q5/partC\n",
    "!mkdir Results/Q5/partD\n",
    "\n",
    "pathA = \"Results/Q5/partA/\"\n",
    "pathB = \"Results/Q5/partB/\"\n",
    "pathC = \"Results/Q5/partC/\"\n",
    "pathD = \"Results/Q5/partD/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd948ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load first image in video\n",
    "vidcap = cv2.VideoCapture(data_path)\n",
    "success,image = vidcap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8685911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image in rgb format\n",
    "# as opencv loads in BGR format by default, we want to show it in RGB.\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86476af7",
   "metadata": {},
   "source": [
    "# Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory to store results\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c245f518",
   "metadata": {},
   "source": [
    "a) Write a function that performs pixel-by-pixel frame differencing using, as reference frame, the first frame of an image sequence. Apply a classification threshold and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef98d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function : performs pixel-by-pixel fram differencing using an image passed in argument as reference frame\n",
    "#            can handle both grayscale and rgb images passed. Takes threshold of difference array to detect\n",
    "#            moving objects.\n",
    "\n",
    "# input : img_curr: Image whose difference we want to take with reference image\n",
    "#         img_ref: referene image\n",
    "#         thr : threshold to classify objects moving\n",
    "#         mode: is the input image grayscale or rgb\n",
    "#         plot_bool : do you want to plot images and save threshold images?\n",
    "\n",
    "# return : difference image after threshold\n",
    "\n",
    "def ICV_frame_differencing(img_curr,img_ref,thr,mode,plot_bool,frame_num,save_path):\n",
    "    # calculate pixel wise absolute percentage difference\n",
    "    diff = abs(img_curr - img_ref)\n",
    "\n",
    "    # display\n",
    "    if mode == 'rgb':\n",
    "        # apply threhold on average difference in RGB \n",
    "        diff_mean = np.mean(diff,axis=2)\n",
    "    \n",
    "    # mean difference in grayscale mode.\n",
    "    if mode == 'gray':\n",
    "        diff_mean = diff\n",
    "    \n",
    "    # if percentage difference compared to reference frame is greater than threshold count as moving object\n",
    "    diff_mean[diff_mean>=thr] = 255\n",
    "    diff_mean[diff_mean<thr] = 0\n",
    "    diff_mean = diff_mean.astype(int)\n",
    "    \n",
    "    if plot_bool == True:\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(diff_mean,cmap='gray')\n",
    "        plt.title(\"Threshold image after frame differencing\")\n",
    "        fig.savefig(save_path+\"Frame_\"+str(frame_num)+\".png\")\n",
    "        plt.show()\n",
    "    \n",
    "    return diff_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7fadf",
   "metadata": {},
   "source": [
    "### Part A attempt 1 : difference original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load first image in video and save it as a reference\n",
    "vidcap = cv2.VideoCapture(data_path)\n",
    "success,image = vidcap.read()\n",
    "image_first = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# loop to go through all the images and get difference with first image.\n",
    "vidcap = cv2.VideoCapture(data_path)\n",
    "i = 0\n",
    "while(1):\n",
    "    print(\"Frame\", i )\n",
    "    i = i + 1\n",
    "    success,image = vidcap.read()\n",
    "    \n",
    "    if i == 1:\n",
    "        continue\n",
    "        \n",
    "    if(success==False):\n",
    "        print(\"break\")\n",
    "        break\n",
    "        \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # set False to True to visualize output\n",
    "    diff_image = ICV_frame_differencing(image,image_first,100,'rgb',False,i,pathA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f65f7",
   "metadata": {},
   "source": [
    "### Part A attempt 2 : take greyscale of original image and then diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load first image in video and save it as a reference\n",
    "vidcap = cv2.VideoCapture(data_path)\n",
    "success,image = vidcap.read()\n",
    "image_first = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_first = image_first[:,:,0]*1/3 + image_first[:,:,1]*1/3 +image_first[:,:,2]*1/3 \n",
    "\n",
    "# loop to go through all the images\n",
    "vidcap = cv2.VideoCapture(data_path)\n",
    "\n",
    "i = 0\n",
    "while(1):\n",
    "    print(\"Frame\", i )\n",
    "    i = i + 1\n",
    "    success,image = vidcap.read()\n",
    "    \n",
    "    if i == 1:\n",
    "        continue\n",
    "        \n",
    "    if(success==False):\n",
    "        print(\"break\")\n",
    "        break\n",
    "        \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # take grayscale of image before differncing\n",
    "    image = image[:,:,0]*1/3 + image[:,:,1]*1/3 +image[:,:,2]*1/3 \n",
    "    \n",
    "    # set False to True to visualize output\n",
    "    diff_image = ICV_frame_differencing(image,image_first,150,'gray',False,i,pathA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9025e",
   "metadata": {},
   "source": [
    "### Part A attempt 3 : take gaussian of original image and then diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from quesiont 2 of corsework\n",
    "\n",
    "# function takes an image and convolution kernel. Does filtering and returns image\n",
    "def ICV_convolution(image,kernel,border_control):\n",
    "    im_width,im_height = image.shape[0],image.shape[1]\n",
    "    k_width,k_height = kernel.shape[0],kernel.shape[1]\n",
    "    \n",
    "    # compute number of pixels to ignore based on kernel dimensions\n",
    "    width_ignore = int(k_width/2)\n",
    "    height_ignore = int(k_height/2)\n",
    "    new_image = np.zeros(image.shape)\n",
    "    \n",
    "    # create an extended old image for handling border issues\n",
    "    extended_img = np.copy(image)\n",
    "    \n",
    "    # based on type of padding \n",
    "    # the matrix to pad will change based on type of control we want at image border\n",
    "    \n",
    "    # pad with zeros\n",
    "    if border_control == \"zeros\":\n",
    "        to_pad_col_1 = np.zeros((image.shape[0],width_ignore,3)).astype(int)\n",
    "        to_pad_col_2 = np.copy(to_pad_col_1)\n",
    "        \n",
    "        to_pad_row_1 = np.zeros((height_ignore,image.shape[1]+width_ignore*2,3)).astype(int)\n",
    "        to_pad_row_2 = np.copy(to_pad_row_1)\n",
    "    \n",
    "    # pad with periodic \n",
    "    if border_control == \"periodic\":\n",
    "        to_pad_col_1 = image[:,:width_ignore,:]\n",
    "        to_pad_col_2 = image[:,-width_ignore:,:]\n",
    "        \n",
    "        to_pad_row_1 = np.zeros((height_ignore,image.shape[1]+width_ignore*2,3)).astype(int)\n",
    "        to_pad_row_1[:,width_ignore:-width_ignore,:] = image[:height_ignore,:,:]\n",
    "        \n",
    "        to_pad_row_2 = np.zeros((height_ignore,image.shape[1]+width_ignore*2,3)).astype(int)\n",
    "        to_pad_row_2[:,width_ignore:-width_ignore,:] = image[-height_ignore:,:,:]\n",
    "    \n",
    "    # pad with mirror image\n",
    "    if border_control == \"mirror\":\n",
    "        to_pad_col_1_temp = image[:,:width_ignore,:]\n",
    "        to_pad_col_2_temp = image[:,-width_ignore:,:]\n",
    "        \n",
    "        to_pad_col_1 = to_pad_col_1_temp.copy()\n",
    "        to_pad_col_2 = to_pad_col_2_temp.copy()\n",
    "        \n",
    "        for k in range(to_pad_col_1_temp.shape[1]):\n",
    "            to_pad_col_1[:,-(k+1),:] = to_pad_col_1_temp[:,k,:]\n",
    "            to_pad_col_2[:,-(k+1),:] = to_pad_col_2_temp[:,k,:]\n",
    "        \n",
    "        to_pad_row_1_temp = np.zeros((height_ignore,image.shape[1]+width_ignore*2,3)).astype(int)\n",
    "        to_pad_row_1_temp[:,width_ignore:-width_ignore,:] = image[:height_ignore,:,:]\n",
    "        \n",
    "        to_pad_row_2_temp = np.zeros((height_ignore,image.shape[1]+width_ignore*2,3)).astype(int)\n",
    "        to_pad_row_2_temp[:,width_ignore:-width_ignore,:] = image[-height_ignore:,:,:]\n",
    "        \n",
    "        to_pad_row_1 = to_pad_row_1_temp.copy()\n",
    "        to_pad_row_2 = to_pad_row_2_temp.copy()\n",
    "        \n",
    "        for k in range(to_pad_row_1_temp.shape[0]):\n",
    "            to_pad_row_1[-(k+1),:,:] = to_pad_row_1_temp[k,:,:]\n",
    "            to_pad_row_2[-(k+1),:,:] = to_pad_row_2_temp[k,:,:]\n",
    "    \n",
    "    # add rows and columns to pad original image\n",
    "    # stack columns\n",
    "    extended_img = np.hstack((to_pad_col_1,image))\n",
    "    extended_img = np.hstack((extended_img,to_pad_col_2))\n",
    "    # stack rows\n",
    "    extended_img = np.vstack((to_pad_row_1,extended_img))\n",
    "    extended_img = np.vstack((extended_img,to_pad_row_2))\n",
    "    \n",
    "    # loop through ell element and apply kernel\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            im_crop = extended_img[i:i+k_width,j:j+k_height]\n",
    "            new_image[i,j,0],new_image[i,j,1],new_image[i,j,2] = np.sum(np.multiply(im_crop[:,:,0],kernel)),np.sum(np.multiply(im_crop[:,:,1],kernel)),np.sum(np.multiply(im_crop[:,:,2],kernel))\n",
    "\n",
    "    return new_image,extended_img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46698970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the gaussian kernel\n",
    "gauss_kernel = np.matrix([[1, 2, 1],[2, 4 ,2],[1 ,2 ,1]])/16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since computing gaussian takes time, we will save these images\n",
    "gauss_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61746714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load first image in video and save it as a reference\n",
    "vidcap = cv2.VideoCapture(data_path)\n",
    "success,image = vidcap.read()\n",
    "image_first = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_first,ext_image = ICV_convolution(image_first,gauss_kernel,\"mirror\")\n",
    "gauss_images.append(image_first)\n",
    "\n",
    "# loop to go through all the images\n",
    "vidcap = cv2.VideoCapture(data_path)\n",
    "\n",
    "i = 0\n",
    "while(1):\n",
    "    print(\"Frame\", i )\n",
    "    i = i + 1\n",
    "    success,image = vidcap.read()\n",
    "    \n",
    "    if i == 1:\n",
    "        continue\n",
    "        \n",
    "    if(success==False):\n",
    "        print(\"break\")\n",
    "        break\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # take gaussian to remove noise\n",
    "    image,ext_image = ICV_convolution(image,gauss_kernel,\"mirror\")\n",
    "    gauss_images.append(image)\n",
    "\n",
    "    diff_image = ICV_frame_differencing(image,image_first,25,'rgb',True,i,pathA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e548b9",
   "metadata": {},
   "source": [
    "## Part b"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fd1ac54",
   "metadata": {},
   "source": [
    "b) Repeat the exercise using the previous frame as reference frame (use frame It-1 as reference frame for frame It, for each t). Comment the results in the report."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f23765ef",
   "metadata": {},
   "source": [
    "Note : Since taking gaussian of image before differencing gives the best result, we will be using that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ab7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop to go through all the images and compute frame difference with previous frame\n",
    "\n",
    "i = 0\n",
    "for image in gauss_images:\n",
    "    print(\"Frame\", i )\n",
    "    i = i + 1\n",
    "    \n",
    "    if i == 1:\n",
    "        # save previous image to take differnce with current image\n",
    "        image_prev = image.copy()\n",
    "        continue\n",
    "    \n",
    "    # perform frame differencing\n",
    "    diff_image = ICV_frame_differencing(image,image_prev,20,'rgb',True,i,pathB)\n",
    "\n",
    "    # update preivous image as current image\n",
    "    image_prev = image.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc9113",
   "metadata": {},
   "source": [
    "## Part C "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0d39d1e",
   "metadata": {},
   "source": [
    "c) Write a function that generates a reference frame (background) for the sequence using for example frame differencing and a weighted temporal averaging algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40c766",
   "metadata": {},
   "source": [
    "### 1) Trying simple weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dde319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns reference image given a list of images using temporal average\n",
    "def ICV_get_ref_frame(image_list):\n",
    "    # loop to go through all the images and take avarage of frames\n",
    "    ref_image = np.zeros(image_list[0].shape)\n",
    "    i = 0\n",
    "    for image in image_list:\n",
    "\n",
    "        ref_image = ref_image + image\n",
    "        i = i+1\n",
    "\n",
    "    ref_image = ref_image/i\n",
    "    return ref_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fad941",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image = ICV_get_ref_frame(gauss_images)\n",
    "fig = plt.figure()\n",
    "plt.imshow(ref_image/np.max(ref_image))\n",
    "plt.title(\"reference image attempt 1\")\n",
    "fig.savefig(pathC+\"weighted_avg.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5353154",
   "metadata": {},
   "source": [
    "## Attempt C.2 : try temporal weighted average with frame differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns reference image given a list of images using temporal average\n",
    "def ICV_get_ref_frame_2(image_list):\n",
    "    # loop to go through all the images and take avarage of frames\n",
    "    ref_image = np.zeros(image_list[0].shape)\n",
    "    i = 0\n",
    "    # keep count of how many times a pixel has been added to in the reference image, to normalize in the end\n",
    "    ref_count = np.zeros(image_list[0].shape)\n",
    "    \n",
    "    for image in image_list:\n",
    "        \n",
    "        if(i==0):\n",
    "            ref_image = ref_image + image\n",
    "            image_prev = image.copy()\n",
    "            ref_count = ref_count + 1\n",
    "        else:\n",
    "            # avoid regions in the image that have difference with previous frame greater than threshold\n",
    "            diff_image = ICV_frame_differencing(image,image_prev,25,'rgb',False,\"random\",'random')\n",
    "            ref_image[diff_image!=255] = ref_image[diff_image!=255] + image[diff_image!=255]\n",
    "            ref_count[diff_image!=255] = ref_count[diff_image!=255] + 1\n",
    "                                                                                                                                     \n",
    "        i = i+1\n",
    "        image_prev = image.copy()\n",
    "    \n",
    "    ref_image = ref_image/ref_count\n",
    "    return ref_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f918ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ref_image_2 = ICV_get_ref_frame_2(gauss_images)\n",
    "plt.imshow(ref_image_2/np.max(ref_image_2))\n",
    "plt.title(\"reference image after differencing and weighted average\")\n",
    "fig.savefig(pathC+\"temporal_diff_weighted_avg.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380bc5f",
   "metadata": {},
   "source": [
    "# Part D: visualise objects being detecting against the reference frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# erosion is a kernel that gives minimum value of all elements in the kernel area.\n",
    "# input : image : image to erode\n",
    "#         border : size of erosion matrix (kernel)\n",
    "# return : image after erosion\n",
    "\n",
    "def ICV_erosion(image,border):\n",
    "    # to deal with borders change size of kernel to limit to pixels in the image\n",
    "    new_image = image.copy()\n",
    "    for i in range(0,image.shape[0]):\n",
    "        for j in range(0,image.shape[1]):\n",
    "            new_image[i,j] = np.min(image[max(i-border,0):min(i+border+1,image.shape[0]-1),max(j-border,0):min(j+border+1,image.shape[1]-1)])\n",
    "            \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilate is a kernel that gives maximum value of all elements in the kernel area.\n",
    "# input : image : image to dilate\n",
    "#         border : size of dilation matrix (kernel)\n",
    "# return : image after dilation\n",
    "\n",
    "def ICV_dilation(image,border):\n",
    "\n",
    "    new_image = image.copy()\n",
    "    for i in range(0,image.shape[0]):\n",
    "        for j in range(0,image.shape[1]):\n",
    "            new_image[i,j] = np.max(image[max(i-border,0):min(i+border+1,image.shape[0]-1),max(j-border,0):min(j+border+1,image.shape[1]-1)])\n",
    "            \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find number of connected components in a matrix\n",
    "# input : image : image to find connected components in\n",
    "# return : matrix with a unique number filled for each connected component\n",
    "\n",
    "def ICV_findIslands(image):\n",
    "    new_image = np.zeros(image.shape)\n",
    "    # to store if we have already visited this pixel\n",
    "    visited = np.zeros(image.shape)\n",
    "    # to keep a count of numbher of connected components detected\n",
    "    car_count = 1\n",
    "    for i in range(20,image.shape[0]-20):\n",
    "        for j in range(20,image.shape[1]-20):\n",
    "            # if component already visited\n",
    "            if visited[i,j] == 1:\n",
    "                continue\n",
    "            if image[i,j]==255:\n",
    "                # if we have not visited this component, find all connected pixels\n",
    "                new_image,visited = ICV_visit_neighbours(image,new_image,visited,car_count,i,j)\n",
    "                car_count = car_count + 1\n",
    "                \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit the 8 neighbours if they have not been visited, recursive function.\n",
    "# input : image to detect connected components in\n",
    "#         new_image : matrix to store result\n",
    "#.        visited : matrix to store what pixels have already been visited\n",
    "#.        row,col : location of starting pixel\n",
    "\n",
    "def ICV_visit_neighbours(image,new_image,visited,car_count,row,col):\n",
    "    \n",
    "    # if pixel location is valid\n",
    "    if(row<0 or row>=image.shape[0] or col<0 or col>=image.shape[1]):\n",
    "        return new_image,visited\n",
    "    # if we have not yet visited this pixel\n",
    "    if(visited[row,col]==1):\n",
    "        return new_image,visited\n",
    "    # if this pixel is not part of the object ,return\n",
    "    if(image[row,col]!=255):\n",
    "        visited[row,col] = 1\n",
    "        return new_image,visited\n",
    "    \n",
    "    visited[row,col] = 1\n",
    "    new_image[row,col] = car_count\n",
    "    \n",
    "    # recursively look at neighboring 8 pixels\n",
    "    for k in [-1,0,1]:\n",
    "        for l in [-1,0,1]:\n",
    "            if(k==0 and l==0):\n",
    "                continue\n",
    "            new_image,visited = ICV_visit_neighbours(image,new_image,visited,car_count,row-k,col-l)\n",
    "    \n",
    "    \n",
    "    return new_image,visited\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns position of all the connected components detected by ICV_findIslands(), \n",
    "# simply take mean of all indexes in the connectd component\n",
    "\n",
    "# input: connected component matrx which has unique value for each connected component\n",
    "# dictionary : with position of each component\n",
    "\n",
    "def ICV_getCarPosition(car_id_array):\n",
    "    id_list = np.unique(car_id_array)\n",
    "    pos_dict = {}\n",
    "    for car_id in id_list:\n",
    "        if(car_id == 0):\n",
    "            continue\n",
    "        indexes = np.where(car_id_array==car_id)\n",
    "        # mean of positions of all pixels in the connected component is its location\n",
    "        x_mean = np.mean(indexes[0])\n",
    "        y_mean = np.mean(indexes[1])\n",
    "        pos_dict[car_id] = [int(np.ceil(x_mean)),int(np.ceil(y_mean))]\n",
    "    return pos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70380aef",
   "metadata": {},
   "source": [
    "# Part D: attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 1: Initial attempt followed the following steps\n",
    "# 1) Take difference of reference image with current image. (all images are gaussian filtered).\n",
    "# 2) dilate and erode the difference matrix to fill in objects.\n",
    "# 3) Find number of connected components in image. This is taken as the number of moving objects.\n",
    "\n",
    "# input : reference image\n",
    "# list of all images in frame after taking gaussian\n",
    "\n",
    "def ICV_get_moving_obj(ref_image,gauss_images):\n",
    "    \n",
    "    # increase limit on recurison for connected component detection\n",
    "    print(sys.getrecursionlimit())\n",
    "    sys.setrecursionlimit(10000)\n",
    "    \n",
    "    i = 0\n",
    "    # stores number of cars in frames\n",
    "    num_cars = []\n",
    "\n",
    "    for image in gauss_images:\n",
    "\n",
    "        print(\"working on frame \", i)\n",
    "        # 1) difference between reference frame and current image\n",
    "        diff_image = ICV_frame_differencing(image,ref_image,50,'rgb',False,\"random\",\"random\")\n",
    "\n",
    "        #  dilation and erosion\n",
    "        mean_diff_dil = diff_image.copy()\n",
    "        for itr in range(2):\n",
    "            mean_diff_dil = ICV_dilation(mean_diff_dil,6)\n",
    "            mean_diff_dil = ICV_erosion(mean_diff_dil,6)\n",
    "\n",
    "        # separate objects\n",
    "        mean_diff_dil = ICV_erosion(mean_diff_dil,1)\n",
    "\n",
    "        # find number of connected components in 2d array, each of these is a car\n",
    "        car_id_array = ICV_findIslands(mean_diff_dil)\n",
    "\n",
    "        # from the above connected components, get positiion of car by taking mean within the component\n",
    "        car_pos = ICV_getCarPosition(car_id_array)\n",
    "        \n",
    "        # store the number of components detected\n",
    "        num_cars.append(len(car_pos.keys()))\n",
    "\n",
    "        i = i+1\n",
    "        \n",
    "    return num_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0cdab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_cars = ICV_get_moving_obj(ref_image,gauss_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(np.arange(len(num_cars)),num_cars)\n",
    "plt.xlabel(\"Frame Number\")\n",
    "plt.ylabel(\"Number of cars\")\n",
    "plt.title(\"Number of cars in the frame\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd236fcd",
   "metadata": {},
   "source": [
    "# Part D: attempt 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2: Track the cars\n",
    "# Note: Entry zones are the zones from which cars can enter. (Bottom right and top left)\n",
    "#           Exit zones are zones from which car can exit (Bottom left and top right)\n",
    "#           This means only objects NOT in entry and exit zones will be counted.\n",
    "\n",
    "# 1) Take difference of reference image with current image. (all images are gaussian filtered).\n",
    "# 2) dilate and erode the difference matrix to fill in objects.\n",
    "# 3) Find number of connected components in image.\n",
    "# 4) Index cars in frame. For every new frame :\n",
    "# \ti) get expected position of car as position in previous frame + expected velocity\n",
    "# \tii) Here, expected velocity is define as average of velocities in previous 10 frames.\n",
    "# 5) To find position of each car in new frame:\n",
    "# \ti) Take difference between expected position of car and all position of connected component in new \tframe.\n",
    "# \tii) the connected component with the minimum distance to expected position is taken as new position.\n",
    "# 6) For those positions in connected components that are unassigned, check if they lie in entry zones.\n",
    "# \ti) if so add new car entry to track.\n",
    "# 7) Similarly, define exit zones for cars, if cars enter these we stop tracking them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bcad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get expected position of car as previous position + expected velocity\n",
    "# input : all_car_pos : dict of car positions for all previous frames\n",
    "#.        key : car whose expected position to find\n",
    "\n",
    "def ICV_get_expected_pos(all_car_pos,key):\n",
    "    # expected velocity of previous frames\n",
    "    expected_velocity = np.diff(all_car_pos[key])\n",
    "    \n",
    "    # if only 1 frame till now\n",
    "    if(expected_velocity.shape[1]<1):\n",
    "        expected_pos = all_car_pos[key][:,-1]\n",
    "    else:\n",
    "        # mean of last 10 velocitites is expected velocity\n",
    "        expected_velocity = np.mean(expected_velocity[:,-np.minimum(all_car_pos[key].shape[1],10):],1)\n",
    "        expected_pos = all_car_pos[key][:,-1] + expected_velocity\n",
    "    return expected_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7c05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for each car in the preivous frame find the best position in current frame depending on expected position\n",
    "# input : all_car_pos : dict of positions of caars in all previous frames\n",
    "#         car_pos : dict of car positions in current frame\n",
    "#.        expected_pos : expectd position of car with id= key\n",
    "#         key : car id\n",
    "def ICV_best_fit(all_car_pos,car_pos,expected_pos,key):\n",
    "    #search in new car positions for nearest best fit position\n",
    "    min_dist = 1e9\n",
    "    key_used = 0\n",
    "    for key2 in car_pos.keys():\n",
    "        dist = np.sum((np.array(car_pos[key2]) - expected_pos)**2)\n",
    "        # find the closest position in new frame\n",
    "        if(dist < min_dist):\n",
    "            new_car_pos = np.array(car_pos[key2])[:,np.newaxis]\n",
    "            min_dist = dist\n",
    "            key_used = key2\n",
    "    return np.hstack((all_car_pos[key],new_car_pos)),key_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to plot trajectory and histogram\n",
    "def ICV_plot_trajectory_and_hist(image,traj,num_cars):\n",
    "    \n",
    "    colors_dict = {}\n",
    "    colors_dict[1] = (255,255,255)\n",
    "    colors_dict[2] = (255,0,0)\n",
    "    colors_dict[3] = (0,255,0)\n",
    "    colors_dict[4] = (0,0,255)\n",
    "    colors_dict[5] = (255,255,0)\n",
    "    colors_dict[6] = (255,0,255)\n",
    "    colors_dict[7] = (0,255,255)\n",
    "    traj_image = np.zeros((image.shape[0],image.shape[1],3))\n",
    "    \n",
    "    count_cars = 0\n",
    "    \n",
    "    for key in traj.keys():\n",
    "        print(traj[key].shape)\n",
    "        for i in range(traj[key].shape[1]):\n",
    "            x = int(traj[key][0,i])\n",
    "            y = int(traj[key][1,i])\n",
    "            traj_image[max(x-1,0):min(x+2,traj_image.shape[0]-1),max(y-1,0):min(y+2,traj_image.shape[1]-1),:] = colors_dict[key]\n",
    "                \n",
    "    fig = plt.figure()\n",
    "    figure(figsize=(8, 6), dpi=80)\n",
    "    plt.title(\"trajectory of all seven cars\")\n",
    "    fig.savefig(pathD+\"trajectory.png\", bbox_inches='tight')\n",
    "    plt.imshow(traj_image/np.max(traj_image))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(np.arange(len(num_cars)),num_cars)\n",
    "    plt.xlabel(\"Frame Number\")\n",
    "    plt.ylabel(\"Number of cars\")\n",
    "    plt.title(\"Number of cars in the frame\")\n",
    "    fig.savefig(pathD+\"BarPlot.png\", bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df136da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with entry exit points\n",
    "\n",
    "def ICV_get_moving_obj_2(ref_image,gauss_images):\n",
    "    \n",
    "    # increasing recursion limit\n",
    "    sys.setrecursionlimit(10000)\n",
    "\n",
    "    i = 0\n",
    "    # list to store number of cars in frames\n",
    "    num_cars_count = []\n",
    "    # store position of cars for all frames\n",
    "    all_car_pos = {}\n",
    "        \n",
    "    for image in gauss_images:\n",
    "\n",
    "        print(\"working on frame \", i)\n",
    "        \n",
    "        # 1) difference between reference frame and current image\n",
    "        diff_image = ICV_frame_differencing(image,ref_image,50,'rgb',False,\"random\",\"random\")\n",
    "        \n",
    "        # try dilation and erosion\n",
    "        mean_diff_dil = diff_image.copy()\n",
    "        for itr in range(2):\n",
    "            mean_diff_dil = ICV_dilation(mean_diff_dil,6)\n",
    "            mean_diff_dil = ICV_erosion(mean_diff_dil,6)\n",
    "\n",
    "        # separate objects\n",
    "        mean_diff_dil = ICV_erosion(mean_diff_dil,1)\n",
    "\n",
    "        # find number of connected components in 2d array, each of these is a car\n",
    "        car_id_array = ICV_findIslands(mean_diff_dil)\n",
    "\n",
    "        # from the above connected components, get positiion of car by taking mean within the component\n",
    "        car_pos = ICV_getCarPosition(car_id_array)\n",
    "        \n",
    "        num_cars_detected = len(car_pos.keys())\n",
    "        # make array to check if all cars in new frame have been assigned to cars in previous frame\n",
    "        car_visited = np.zeros((num_cars_detected+1))\n",
    "        \n",
    "        count_curr = 0\n",
    "        # initial conditions if first frame\n",
    "        if(i==0):\n",
    "            for key in car_pos.keys():\n",
    "                pos_temp = np.ones((2,1))\n",
    "                pos_temp[0,0] = car_pos[key][0]\n",
    "                pos_temp[1,0] = car_pos[key][1]\n",
    "                all_car_pos[key] = pos_temp.copy()\n",
    "            num_cars_count.append(len(car_pos.keys()))\n",
    "            expected_pos = car_pos.copy()\n",
    "        \n",
    "        else:\n",
    "            # update expected car positions\n",
    "            for key in all_car_pos.keys():\n",
    "                expected_pos = ICV_get_expected_pos(all_car_pos,key)\n",
    "                \n",
    "                # define exit zones\n",
    "                exit1 = expected_pos[0]>200 and expected_pos[1]<50\n",
    "                exit2 = expected_pos[0]<30 and expected_pos[1] < 150\n",
    "                exit3 = expected_pos[0]>250 and expected_pos[1]<100\n",
    "                \n",
    "                # if car in exit zones then assign previous position\n",
    "                if(exit1 or exit2 or exit3):\n",
    "                    all_car_pos[key] = np.hstack((all_car_pos[key],all_car_pos[key][:,-1][:,np.newaxis]))\n",
    "                else:\n",
    "                    #search in new car positions for nearest expected position\n",
    "                    all_car_pos[key],key_used = ICV_best_fit(all_car_pos,car_pos,expected_pos,key)\n",
    "                    car_visited[int(key_used)] = 1\n",
    "                    count_curr = count_curr + 1\n",
    "                \n",
    "            # enter unassigned cars as new entries only if they are in entry zones\n",
    "            for key in range(1,car_visited.shape[0]):\n",
    "                entry1 = car_pos[key][0]<30 and car_pos[key][1]<150\n",
    "                entry2 = car_pos[key][0]>250 and car_pos[key][1]>200\n",
    "                if car_visited[key]==1:\n",
    "                    continue\n",
    "                if(entry1 or entry2):\n",
    "                    # add new car\n",
    "                    key_added = len(all_car_pos.keys())+1\n",
    "                    all_car_pos[key_added] = np.array((2,1))[:,np.newaxis]\n",
    "                    all_car_pos[key_added][0,0] = car_pos[key][0]\n",
    "                    all_car_pos[key_added][1,0] = car_pos[key][1]\n",
    "                    count_curr = count_curr + 1\n",
    "                    \n",
    "        \n",
    "        num_cars_count.append(count_curr)\n",
    "\n",
    "        i = i+1\n",
    "    ICV_plot_trajectory_and_hist(image,all_car_pos,num_cars_count)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11367db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ICV_get_moving_obj_2(ref_image,gauss_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4955d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
